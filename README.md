# transformers
"Implementing Transformers from scratch using PyTorch &amp; NumPy, covering Positional Encoding, Self-Attention, Multi-Head Attention, Layer Normalization, Encoder, and Decoder. A complete deep-dive into the Transformer architecture!"
